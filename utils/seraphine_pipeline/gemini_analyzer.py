"""
Gemini LLM analyzer utility for grouped icon images
Sends Seraphine-generated grouped images to Gemini for intelligent analysis
"""

import os
import json
import asyncio
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
from PIL import Image
from datetime import datetime
from .helpers import debug_print

try:
    from google import genai
    from google.genai.errors import ServerError
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False
    debug_print("âš ï¸  Warning: google-genai not installed. Gemini analysis will be skipped.")

try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    debug_print("âš ï¸  Warning: python-dotenv not installed. Make sure GEMINI_API_KEY is set manually.")


class GeminiIconAnalyzer:
    """
    Analyzes grouped icon images using Gemini LLM
    Takes Seraphine-generated final_*.png images and identifies icons with usage descriptions
    """
    
    def __init__(self, prompt_path: str = None, 
                 output_dir: str = "outputs", 
                 max_concurrent_requests: int = 4,
                 save_results: bool = True):
        self.output_dir = output_dir
        
        # Fix: Handle prompt path correctly
        if prompt_path is None:
            # Default case: find prompt.txt in the same directory as this module
            module_dir = os.path.dirname(os.path.abspath(__file__))
            self.prompt_path = os.path.join(module_dir, "prompt.txt")
        else:
            # Custom case: use the provided path as-is (relative to working directory)
            # Don't append to module directory!
            self.prompt_path = prompt_path
        
        self.max_concurrent_requests = max_concurrent_requests
        self.save_results = save_results
        
        if not GEMINI_AVAILABLE:
            raise ImportError("google-genai package not installed. Install with: pip install google-genai")
        
        # Initialize Gemini client
        self.api_key = os.getenv("GEMINI_API_KEY")
        if not self.api_key:
            raise ValueError("GEMINI_API_KEY not found in environment variables")
        
        self.client = genai.Client(api_key=self.api_key)
        self.prompt = self._load_prompt()
        
        debug_print(f"ðŸ¤– Gemini analyzer initialized with prompt from: {self.prompt_path}")
    
    def _load_prompt(self) -> str:
        """Load the analysis prompt from file"""
        try:
            with open(self.prompt_path, "r", encoding="utf-8") as f:
                prompt_content = f.read().strip()
            print(f"ðŸ¤– [GEMINI] âœ… Loaded prompt from: {self.prompt_path}")
            print(f"ðŸ¤– [GEMINI]    Prompt length: {len(prompt_content)} characters")
            print(f"ðŸ¤– [GEMINI]    Full prompt content:")
            print("ðŸ¤– [GEMINI] " + "="*80)
            # Show full prompt (it's important to see what we're sending)
            for line in prompt_content.split('\n'):
                print(f"ðŸ¤– [GEMINI] {line}")
            print("ðŸ¤– [GEMINI] " + "="*80)
            debug_print(f"âœ… Loaded prompt ({len(prompt_content)} characters)")
            return prompt_content
        except FileNotFoundError:
            print(f"ðŸ¤– [GEMINI] âŒ ERROR: Prompt file not found: {self.prompt_path}")
            raise FileNotFoundError(f"Prompt file not found: {self.prompt_path}")
    
    async def analyze_grouped_images(self, grouped_image_paths: List[str] = None, 
                                   filename_base: str = None,
                                   direct_images: List[Tuple] = None) -> Dict[str, Any]:
        """
        Analyze grouped images generated by Seraphine
        
        Args:
            grouped_image_paths: List of paths to final_*.png images (traditional method)
            filename_base: Base filename for saving results
            direct_images: List of (PIL.Image, filename) tuples (optimized method)
            
        Returns:
            Dictionary containing analysis results
        """
        if direct_images:
            print(f"ðŸ¤– [GEMINI] Starting Gemini analysis of {len(direct_images)} grouped images (direct mode)...")
            valid_images = [(img, name) for img, name in direct_images if "combined" in name]
            debug_print(f"\nðŸ¤– Starting Gemini analysis of {len(direct_images)} grouped images (direct mode)...")
        elif grouped_image_paths:
            print(f"ðŸ¤– [GEMINI] Starting Gemini analysis of {len(grouped_image_paths)} grouped images (file mode)...")
            debug_print(f"\nðŸ¤– Starting Gemini analysis of {len(grouped_image_paths)} grouped images (file mode)...")
            valid_image_paths = [
                image_path for image_path in sorted(grouped_image_paths) 
                if "combined" in os.path.basename(image_path)
            ]
            valid_images = [(path, os.path.basename(path)) for path in valid_image_paths]
        else:
            print("ðŸ¤– [GEMINI] âŒ ERROR: No images provided (both direct_images and grouped_image_paths are None/empty)")
            print("ðŸ¤– [GEMINI]    This usually means all groups have explore=False, so no images were generated")
            print("ðŸ¤– [GEMINI]    Check seraphine_preprocessor.py to see why explore flags are False")
            return {
                'images': [], 
                'total_icons_found': 0, 
                'analysis_duration_seconds': 0,
                'total_images_analyzed': 0,
                'successful_analyses': 0,
                'analysis_success': False,
                'error': 'No images to analyze - all groups have explore=False'
            }
        
        if not valid_images:
            print("ðŸ¤– [GEMINI] âŒ No valid combined images found for analysis")
            print("ðŸ¤– [GEMINI]    Images must contain 'combined' in filename")
            debug_print("âŒ No valid combined images found for analysis")
            return {
                'images': [], 
                'total_icons_found': 0, 
                'analysis_duration_seconds': 0,
                'total_images_analyzed': 0,
                'successful_analyses': 0,
                'analysis_success': False,
                'error': 'No valid combined images found'
            }
        
        # Start timing
        start_time = datetime.now()
        
        debug_print(f"  ðŸ“¸ Starting parallel analysis of {len(valid_images)} images...")
        
        # Execute all tasks in parallel with concurrency limit
        semaphore = asyncio.Semaphore(self.max_concurrent_requests)
        
        # Modified analysis function with semaphore for direct images
        async def analyze_and_process_image_direct(image_data, filename: str, index: int) -> Dict[str, Any]:
            """Analyze a single image with concurrency control - supports both file paths and PIL images"""
            async with semaphore:
                debug_print(f"  ðŸ“¸ Analyzing image {index+1}/{len(valid_images)}: {filename}")
                
                try:
                    # Analyze with Gemini - supports both PIL and file path
                    response = await self._analyze_single_image_direct(image_data, filename)
                    
                    if response:
                        icons = self._parse_gemini_response(response)
                        
                        # âœ… DEBUG: Show parsed icons
                        print(f"ðŸ¤– [GEMINI] Parsed {len(icons)} icons from response:")
                        for i, icon in enumerate(icons[:5]):  # Show first 5
                            print(f"ðŸ¤– [GEMINI]   Icon {i+1}: ID={icon.get('id')}, Name='{icon.get('name')}', Usage='{icon.get('usage', '')[:50]}...'")
                        if len(icons) > 5:
                            print(f"ðŸ¤– [GEMINI]   ... and {len(icons) - 5} more icons")
                        
                        image_result = {
                            'image_path': filename if isinstance(image_data, str) else f"direct:{filename}",
                            'image_name': filename,
                            'icons_found': len(icons),
                            'icons': icons,
                            'raw_response': response,
                            'analysis_success': True
                        }
                        
                        debug_print(f"    âœ… Found {len(icons)} icons in {filename}")
                        return image_result
                    else:
                        image_result = {
                            'image_path': filename if isinstance(image_data, str) else f"direct:{filename}",
                            'image_name': filename,
                            'icons_found': 0,
                            'icons': [],
                            'raw_response': None,
                            'analysis_success': False,
                            'error': 'Failed to get response from Gemini'
                        }
                        debug_print(f"    âŒ Analysis failed for {filename}")
                        return image_result
                    
                except Exception as e:
                    debug_print(f"    âŒ Error analyzing {filename}: {str(e)}")
                    return {
                        'image_path': filename if isinstance(image_data, str) else f"direct:{filename}",
                        'image_name': filename,
                        'icons_found': 0,
                        'icons': [],
                        'raw_response': None,
                        'analysis_success': False,
                        'error': str(e)
                    }
        
        # Create tasks for all images
        tasks = []
        for i, (image_data, filename) in enumerate(valid_images):
            tasks.append(analyze_and_process_image_direct(image_data, filename, i))
        
        debug_print(f"ðŸš€ Executing {len(tasks)} requests to Gemini (max {self.max_concurrent_requests} concurrent)...")
        image_results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Handle any exceptions from gather
        processed_results = []
        total_icons_found = 0
        
        for i, result in enumerate(image_results):
            if isinstance(result, Exception):
                error_result = {
                    'image_path': f"direct:{valid_images[i][1]}" if direct_images else valid_images[i][0],
                    'image_name': valid_images[i][1],
                    'icons_found': 0,
                    'icons': [],
                    'raw_response': None,
                    'analysis_success': False,
                    'error': f'Task exception: {str(result)}'
                }
                processed_results.append(error_result)
                debug_print(f"    âŒ Task exception for {valid_images[i][1]}: {result}")
            else:
                processed_results.append(result)
                if result['analysis_success']:
                    total_icons_found += result['icons_found']
        
        image_results = processed_results
        
        end_time = datetime.now()
        analysis_duration = (end_time - start_time).total_seconds()
        
        # Compile final results
        results = {
            'filename_base': filename_base,
            'analysis_timestamp': end_time.isoformat(),
            'analysis_duration_seconds': analysis_duration,
            'total_images_analyzed': len(valid_images),
            'total_input_images': len(direct_images) if direct_images else (len(grouped_image_paths) if grouped_image_paths else 0),
            'analysis_mode': 'direct' if direct_images else 'file',
            'successful_analyses': len([r for r in image_results if r['analysis_success']]),
            'total_icons_found': total_icons_found,
            'images': image_results
        }
        
        # Save results
        results_path = self._save_analysis_results(results, filename_base)
        results['results_saved_to'] = results_path
        
        # Display summary
        self._display_analysis_summary(results)
        
        debug_print(f"ðŸŽ‰ Gemini analysis completed in {analysis_duration:.2f}s")
        return results
    
    async def _analyze_single_image_direct(self, image_data, filename: str, max_retries: int = 3) -> Optional[str]:
        """Analyze a single image with Gemini - supports both PIL images and file paths with retry logic for 429 errors"""
        import time
        
        if isinstance(image_data, str):
            # Traditional file path method
            image = Image.open(image_data)
        else:
            # Direct PIL image method (optimization!)
            image = image_data
        
        # âœ… DEBUG: Show that we're calling Gemini
        print(f"\nðŸ¤– [GEMINI] Calling Gemini API for image: {filename}")
        print(f"ðŸ¤– [GEMINI] Model: gemini-2.0-flash-exp")
        print(f"ðŸ¤– [GEMINI] Image size: {image.size if hasattr(image, 'size') else 'N/A'}")
        
        # âœ… DEBUG: Show the prompt being sent (first 500 chars)
        prompt_preview = self.prompt[:500] + "..." if len(self.prompt) > 500 else self.prompt
        print(f"ðŸ¤– [GEMINI] Prompt preview (first 500 chars):")
        print(f"ðŸ¤– [GEMINI] {prompt_preview}")
        print(f"ðŸ¤– [GEMINI] Full prompt length: {len(self.prompt)} characters")
        
        # Retry logic for rate limiting (429 errors)
        for attempt in range(max_retries):
            try:
                # Call Gemini API
                if attempt > 0:
                    wait_time = 2 ** attempt  # Exponential backoff: 2s, 4s, 8s
                    print(f"ðŸ¤– [GEMINI] â³ Retry attempt {attempt + 1}/{max_retries} after {wait_time}s wait...")
                    await asyncio.sleep(wait_time)
                else:
                    print(f"ðŸ¤– [GEMINI] Sending request to Gemini API...")
                
                response = await self.client.aio.models.generate_content(
                    model="gemini-2.0-flash-exp",
                    contents=[self.prompt, image],
                )
                
                response_text = response.text
                print(f"ðŸ¤– [GEMINI] âœ… Received response from Gemini!")
                print(f"ðŸ¤– [GEMINI] Response length: {len(response_text)} characters")
                
                # âœ… DEBUG: Show response preview (first 1000 chars)
                response_preview = response_text[:1000] + "..." if len(response_text) > 1000 else response_text
                print(f"ðŸ¤– [GEMINI] Response preview (first 1000 chars):")
                print(f"ðŸ¤– [GEMINI] {response_preview}")
                print(f"ðŸ¤– [GEMINI] {'='*80}\n")
                
                return response_text
                
            except ServerError as e:
                error_str = str(e)
                # Check if it's a 429 rate limit error
                if "429" in error_str or "rate limit" in error_str.lower() or "quota" in error_str.lower():
                    if attempt < max_retries - 1:
                        wait_time = 2 ** (attempt + 1)  # Exponential backoff
                        print(f"ðŸ¤– [GEMINI] âš ï¸  Rate limit error (429) - will retry in {wait_time}s...")
                        print(f"ðŸ¤– [GEMINI]    Error: {error_str}")
                        await asyncio.sleep(wait_time)
                        continue
                    else:
                        print(f"ðŸ¤– [GEMINI] âŒ Rate limit error (429) - max retries ({max_retries}) exceeded")
                        print(f"ðŸ¤– [GEMINI]    Error: {error_str}")
                        print(f"ðŸ¤– [GEMINI]    Please wait a few minutes and try again, or reduce gemini_max_concurrent in config")
                        return None
                else:
                    # Other server errors - don't retry
                    print(f"ðŸ¤– [GEMINI] âŒ Server error from Gemini API: {e}")
                    debug_print(f"    âš ï¸  Server error: {e}")
                    return None
                    
            except Exception as e:
                error_str = str(e)
                # Check if it's a 429 rate limit error in exception message
                if "429" in error_str or "rate limit" in error_str.lower() or "quota" in error_str.lower():
                    if attempt < max_retries - 1:
                        wait_time = 2 ** (attempt + 1)
                        print(f"ðŸ¤– [GEMINI] âš ï¸  Rate limit error (429) - will retry in {wait_time}s...")
                        print(f"ðŸ¤– [GEMINI]    Error: {error_str}")
                        await asyncio.sleep(wait_time)
                        continue
                    else:
                        print(f"ðŸ¤– [GEMINI] âŒ Rate limit error (429) - max retries ({max_retries}) exceeded")
                        print(f"ðŸ¤– [GEMINI]    Error: {error_str}")
                        return None
                else:
                    # Other errors - don't retry
                    print(f"ðŸ¤– [GEMINI] âŒ Analysis error: {e}")
                    import traceback
                    print(f"ðŸ¤– [GEMINI] Full error traceback:")
                    traceback.print_exc()
                    debug_print(f"    âŒ Analysis error: {e}")
                    return None
        
        # If we get here, all retries failed
        print(f"ðŸ¤– [GEMINI] âŒ All {max_retries} retry attempts failed")
        return None
    
    def _parse_gemini_response(self, response_text: str) -> List[Dict[str, str]]:
        """Parse Gemini response into structured icon data"""
        if not response_text:
            return []
        
        icons = []
        lines = response_text.strip().split('\n')
        
        for line in lines:
            line = line.strip()
            
            # Skip empty lines and lines that don't start with group identifiers
            if not line or not line.startswith(('H', 'V', 'U')):
                continue
            
            try:
                # Parse format: ID: "icon_name" | Usage: "brief explanation" | Enabled: "true/false" | Interactive: "true/false" | Type: "icon/text"
                if line.count('|') >= 4 and ':' in line:  # Now expect 5 parts
                    parts = line.split('|')
                    id_part = parts[0]
                    usage_part = parts[1] 
                    enabled_part = parts[2]
                    interactive_part = parts[3]
                    type_part = parts[4]
                    
                    # Extract ID and name
                    id_section = id_part.split(':', 1)
                    if len(id_section) == 2:
                        icon_id = id_section[0].strip()
                        icon_name = id_section[1].strip().strip('"')
                        
                        # Extract usage
                        usage = usage_part.replace('Usage:', '').strip().strip('"')
                        
                        # Extract enabled and interactive
                        enabled = enabled_part.replace('Enabled:', '').strip().strip('"').lower() == 'true'
                        interactive = interactive_part.replace('Interactive:', '').strip().strip('"').lower() == 'true'
                        
                        # Extract type
                        g_type = type_part.replace('Type:', '').strip().strip('"').lower()
                        if g_type not in ['icon', 'text']:
                            g_type = 'icon'  # Default fallback
                        
                        icons.append({
                            'id': icon_id,
                            'name': icon_name,
                            'usage': usage,
                            'enabled': enabled,
                            'interactive': interactive,
                            'type': g_type,  # New field
                            'group_type': icon_id[0] if icon_id else 'unknown'
                        })
                        
            except Exception as e:
                debug_print(f"    âš ï¸  Failed to parse line: '{line}' - {e}")
                continue
        
        return icons
    
    def _save_analysis_results(self, results: Dict[str, Any], filename_base: str) -> str:
        """Save analysis results to JSON file (only if enabled) - SINGLE FILE ONLY"""
        if not self.save_results:
            return None  # Skip saving if disabled
        
        current_time = datetime.now().strftime("%H-%M")
        
        # Save only ONE file with all the details (remove redundant summary)
        analysis_path = os.path.join(self.output_dir, f"{filename_base}_gemini_analysis_{current_time}.json")
        
        # Save complete results (with structured data AND raw responses for debugging)
        with open(analysis_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        debug_print(f"ðŸ’¾ Saved Gemini analysis: {os.path.basename(analysis_path)}")
        
        return analysis_path
    
    def _display_analysis_summary(self, results: Dict[str, Any]):
        """Display a formatted summary of analysis results"""
        debug_print(f"\nðŸ¤– GEMINI ANALYSIS SUMMARY:")
        debug_print("=" * 60)
        debug_print(f"  ðŸ“Š Images analyzed: {results['successful_analyses']}/{results['total_images_analyzed']}")
        debug_print(f"  ðŸŽ¯ Total icons found: {results['total_icons_found']}")
        debug_print(f"  â±ï¸  Analysis time: {results['analysis_duration_seconds']:.2f}s")
        
        # Group icons by type
        icon_counts = {'H': 0, 'V': 0, 'U': 0}
        all_icons = []
        
        for image_result in results['images']:
            if image_result['analysis_success']:
                for icon in image_result['icons']:
                    all_icons.append(icon)
                    group_type = icon.get('group_type', 'U')
                    icon_counts[group_type] = icon_counts.get(group_type, 0) + 1
        
        debug_print(f"\nðŸ“‹ ICON BREAKDOWN:")
        debug_print(f"  ðŸ”„ Horizontal groups (H): {icon_counts['H']} icons")
        debug_print(f"  ðŸ“Š Vertical groups (V): {icon_counts['V']} icons") 
        debug_print(f"  ðŸ” Ungrouped (U): {icon_counts['U']} icons")
        
        # Show sample icons
        if all_icons:
            debug_print(f"\nðŸŽ¨ SAMPLE ICONS FOUND:")
            for i, icon in enumerate(all_icons[:5]):  # Show first 5
                debug_print(f"  {icon['id']}: \"{icon['name']}\" | {icon['usage'][:50]}...")
            
            if len(all_icons) > 5:
                debug_print(f"  ... and {len(all_icons) - 5} more icons")
        
        debug_print("=" * 60)
