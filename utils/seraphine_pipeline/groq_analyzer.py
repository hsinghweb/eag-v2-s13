"""
Groq LLM analyzer utility for grouped icon images
Sends Seraphine-generated grouped images to Groq for intelligent analysis
"""

import os
import json
import asyncio
import base64
import io
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
from PIL import Image
from datetime import datetime
from .helpers import debug_print

try:
    from groq import Groq
    GROQ_AVAILABLE = True
except ImportError:
    GROQ_AVAILABLE = False
    debug_print("âš ï¸  Warning: groq package not installed. Install with: pip install groq")

try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    debug_print("âš ï¸  Warning: python-dotenv not installed. Make sure GROQ_API_KEY is set manually.")


class GroqIconAnalyzer:
    """
    Analyzes grouped icon images using Groq LLM
    Takes Seraphine-generated final_*.png images and identifies icons with usage descriptions
    """
    
    def __init__(self, prompt_path: str = None, 
                 output_dir: str = "outputs", 
                 max_concurrent_requests: int = 4,
                 save_results: bool = True,
                 model: str = "llama-3.3-70b-versatile"):
        self.output_dir = output_dir
        self.model = model
        
        # Fix: Handle prompt path correctly
        if prompt_path is None:
            # Default case: find prompt.txt in the same directory as this module
            module_dir = os.path.dirname(os.path.abspath(__file__))
            self.prompt_path = os.path.join(module_dir, "prompt.txt")
        else:
            # Custom case: use the provided path as-is (relative to working directory)
            self.prompt_path = prompt_path
        
        self.max_concurrent_requests = max_concurrent_requests
        self.save_results = save_results
        
        if not GROQ_AVAILABLE:
            raise ImportError("groq package not installed. Install with: pip install groq")
        
        # Initialize Groq client
        self.api_key = os.getenv("GROQ_API_KEY")
        if not self.api_key:
            raise ValueError("GROQ_API_KEY not found in environment variables")
        
        self.client = Groq(api_key=self.api_key)
        self.prompt = self._load_prompt()
        
        print(f"ğŸš€ [GROQ] Groq analyzer initialized with model: {self.model}")
        debug_print(f"ğŸš€ Groq analyzer initialized with prompt from: {self.prompt_path}")
    
    def _load_prompt(self) -> str:
        """Load the analysis prompt from file"""
        try:
            with open(self.prompt_path, "r", encoding="utf-8") as f:
                prompt_content = f.read().strip()
            print(f"ğŸš€ [GROQ] âœ… Loaded prompt from: {self.prompt_path}")
            print(f"ğŸš€ [GROQ]    Prompt length: {len(prompt_content)} characters")
            print(f"ğŸš€ [GROQ]    Full prompt content:")
            print("ğŸš€ [GROQ] " + "="*80)
            # Show full prompt (it's important to see what we're sending)
            for line in prompt_content.split('\n'):
                print(f"ğŸš€ [GROQ] {line}")
            print("ğŸš€ [GROQ] " + "="*80)
            debug_print(f"âœ… Loaded prompt ({len(prompt_content)} characters)")
            return prompt_content
        except FileNotFoundError:
            print(f"ğŸš€ [GROQ] âŒ ERROR: Prompt file not found: {self.prompt_path}")
            raise FileNotFoundError(f"Prompt file not found: {self.prompt_path}")
    
    def _image_to_base64(self, image: Image.Image) -> str:
        """Convert PIL Image to base64 string for Groq API"""
        buffered = io.BytesIO()
        image.save(buffered, format="PNG")
        img_str = base64.b64encode(buffered.getvalue()).decode()
        return img_str
    
    async def analyze_grouped_images(self, grouped_image_paths: List[str] = None, 
                                   filename_base: str = None,
                                   direct_images: List[Tuple] = None) -> Dict[str, Any]:
        """
        Analyze grouped images generated by Seraphine
        
        Args:
            grouped_image_paths: List of paths to final_*.png images (traditional method)
            filename_base: Base filename for saving results
            direct_images: List of (PIL.Image, filename) tuples (optimized method)
            
        Returns:
            Dictionary containing analysis results
        """
        if direct_images:
            print(f"ğŸš€ [GROQ] Starting Groq analysis of {len(direct_images)} grouped images (direct mode)...")
            valid_images = [(img, name) for img, name in direct_images if "combined" in name]
            debug_print(f"\nğŸš€ Starting Groq analysis of {len(direct_images)} grouped images (direct mode)...")
        elif grouped_image_paths:
            print(f"ğŸš€ [GROQ] Starting Groq analysis of {len(grouped_image_paths)} grouped images (file mode)...")
            debug_print(f"\nğŸš€ Starting Groq analysis of {len(grouped_image_paths)} grouped images (file mode)...")
            valid_image_paths = [
                image_path for image_path in sorted(grouped_image_paths) 
                if "combined" in os.path.basename(image_path)
            ]
            valid_images = [(path, os.path.basename(path)) for path in valid_image_paths]
        else:
            print("ğŸš€ [GROQ] âŒ ERROR: No images provided (both direct_images and grouped_image_paths are None/empty)")
            print("ğŸš€ [GROQ]    This usually means all groups have explore=False, so no images were generated")
            return {
                'images': [], 
                'total_icons_found': 0, 
                'analysis_duration_seconds': 0,
                'total_images_analyzed': 0,
                'successful_analyses': 0,
                'analysis_success': False,
                'error': 'No images to analyze - all groups have explore=False'
            }
        
        if not valid_images:
            print("ğŸš€ [GROQ] âŒ No valid combined images found for analysis")
            print("ğŸš€ [GROQ]    Images must contain 'combined' in filename")
            debug_print("âŒ No valid combined images found for analysis")
            return {
                'images': [], 
                'total_icons_found': 0, 
                'analysis_duration_seconds': 0,
                'total_images_analyzed': 0,
                'successful_analyses': 0,
                'analysis_success': False,
                'error': 'No valid combined images found'
            }
        
        # Start timing
        start_time = datetime.now()
        
        print(f"ğŸš€ [GROQ]  ğŸ“¸ Starting parallel analysis of {len(valid_images)} images...")
        debug_print(f"  ğŸ“¸ Starting parallel analysis of {len(valid_images)} images...")
        
        # Execute all tasks in parallel with concurrency limit
        semaphore = asyncio.Semaphore(self.max_concurrent_requests)
        
        # Modified analysis function with semaphore for direct images
        async def analyze_and_process_image_direct(image_data, filename: str, index: int) -> Dict[str, Any]:
            """Analyze a single image with concurrency control - supports both file paths and PIL images"""
            async with semaphore:
                try:
                    if isinstance(image_data, str):
                        # File path mode
                        response = await self._analyze_single_image_direct(image_data, filename)
                    else:
                        # Direct PIL image mode
                        response = await self._analyze_single_image_direct(image_data, filename)
                    
                    if response:
                        icons = self._parse_groq_response(response)
                        
                        # âœ… DEBUG: Show parsed icons
                        print(f"ğŸš€ [GROQ] Parsed {len(icons)} icons from response:")
                        for i, icon in enumerate(icons[:5]):  # Show first 5
                            print(f"ğŸš€ [GROQ]   Icon {i+1}: ID={icon.get('id')}, Name='{icon.get('name')}', Usage='{icon.get('usage', '')[:50]}...'")
                        if len(icons) > 5:
                            print(f"ğŸš€ [GROQ]   ... and {len(icons) - 5} more icons")
                        
                        image_result = {
                            'image_path': filename if isinstance(image_data, str) else f"direct:{filename}",
                            'image_name': filename,
                            'icons_found': len(icons),
                            'icons': icons,
                            'raw_response': response,
                            'analysis_success': True
                        }
                        
                        debug_print(f"    âœ… Found {len(icons)} icons in {filename}")
                        return image_result
                    else:
                        return {
                            'image_path': filename if isinstance(image_data, str) else f"direct:{filename}",
                            'image_name': filename,
                            'icons_found': 0,
                            'icons': [],
                            'raw_response': None,
                            'analysis_success': False,
                            'error': 'No response from Groq'
                        }
                except Exception as e:
                    debug_print(f"    âŒ Error analyzing {filename}: {e}")
                    return {
                        'image_path': filename if isinstance(image_data, str) else f"direct:{filename}",
                        'image_name': filename,
                        'icons_found': 0,
                        'icons': [],
                        'raw_response': None,
                        'analysis_success': False,
                        'error': str(e)
                    }
        
        # Create tasks for all images
        tasks = [
            analyze_and_process_image_direct(img, name, i) 
            for i, (img, name) in enumerate(valid_images)
        ]
        
        # Execute all tasks
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Process results
        processed_results = []
        total_icons_found = 0
        
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                error_result = {
                    'image_path': valid_images[i][1] if i < len(valid_images) else 'unknown',
                    'image_name': valid_images[i][1] if i < len(valid_images) else 'unknown',
                    'icons_found': 0,
                    'icons': [],
                    'raw_response': None,
                    'analysis_success': False,
                    'error': f'Task exception: {str(result)}'
                }
                processed_results.append(error_result)
                debug_print(f"    âŒ Task exception for {valid_images[i][1]}: {result}")
            else:
                processed_results.append(result)
                if result['analysis_success']:
                    total_icons_found += result['icons_found']
        
        image_results = processed_results
        
        end_time = datetime.now()
        analysis_duration = (end_time - start_time).total_seconds()
        
        # Compile final results
        results = {
            'filename_base': filename_base,
            'analysis_timestamp': end_time.isoformat(),
            'analysis_duration_seconds': analysis_duration,
            'total_images_analyzed': len(valid_images),
            'total_input_images': len(direct_images) if direct_images else (len(grouped_image_paths) if grouped_image_paths else 0),
            'analysis_mode': 'direct' if direct_images else 'file',
            'successful_analyses': len([r for r in image_results if r['analysis_success']]),
            'total_icons_found': total_icons_found,
            'images': image_results
        }
        
        # Save results
        results_path = self._save_analysis_results(results, filename_base)
        results['results_saved_to'] = results_path
        
        # Display summary
        self._display_analysis_summary(results)
        
        debug_print(f"ğŸ‰ Groq analysis completed in {analysis_duration:.2f}s")
        return results
    
    async def _analyze_single_image_direct(self, image_data, filename: str, max_retries: int = 3) -> Optional[str]:
        """Analyze a single image with Groq - supports both PIL images and file paths with retry logic for 429 errors"""
        import time
        
        if isinstance(image_data, str):
            # Traditional file path method
            image = Image.open(image_data)
        else:
            # Direct PIL image method (optimization!)
            image = image_data
        
        # âœ… DEBUG: Show that we're calling Groq
        print(f"\nğŸš€ [GROQ] Calling Groq API for image: {filename}")
        print(f"ğŸš€ [GROQ] Model: {self.model}")
        print(f"ğŸš€ [GROQ] Image size: {image.size if hasattr(image, 'size') else 'N/A'}")
        
        # âœ… DEBUG: Show the prompt being sent (first 500 chars)
        prompt_preview = self.prompt[:500] + "..." if len(self.prompt) > 500 else self.prompt
        print(f"ğŸš€ [GROQ] Prompt preview (first 500 chars):")
        print(f"ğŸš€ [GROQ] {prompt_preview}")
        print(f"ğŸš€ [GROQ] Full prompt length: {len(self.prompt)} characters")
        
        # Convert image to base64 for Groq API
        image_base64 = self._image_to_base64(image)
        
        # Retry logic for rate limiting (429 errors)
        for attempt in range(max_retries):
            try:
                # Call Groq API
                if attempt > 0:
                    wait_time = 2 ** attempt  # Exponential backoff: 2s, 4s, 8s
                    print(f"ğŸš€ [GROQ] â³ Retry attempt {attempt + 1}/{max_retries} after {wait_time}s wait...")
                    await asyncio.sleep(wait_time)
                else:
                    print(f"ğŸš€ [GROQ] Sending request to Groq API...")
                
                # Groq API call with image
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {
                            "role": "user",
                            "content": [
                                {"type": "text", "text": self.prompt},
                                {
                                    "type": "image_url",
                                    "image_url": {
                                        "url": f"data:image/png;base64,{image_base64}"
                                    }
                                }
                            ]
                        }
                    ],
                    temperature=0.1,
                    max_tokens=4096
                )
                
                response_text = response.choices[0].message.content
                print(f"ğŸš€ [GROQ] âœ… Received response from Groq!")
                print(f"ğŸš€ [GROQ] Response length: {len(response_text)} characters")
                
                # âœ… DEBUG: Show response preview (first 1000 chars)
                response_preview = response_text[:1000] + "..." if len(response_text) > 1000 else response_text
                print(f"ğŸš€ [GROQ] Response preview (first 1000 chars):")
                print(f"ğŸš€ [GROQ] {response_preview}")
                print(f"ğŸš€ [GROQ] {'='*80}\n")
                
                return response_text
                
            except Exception as e:
                error_str = str(e)
                # Check if it's a 429 rate limit error
                if "429" in error_str or "rate limit" in error_str.lower() or "quota" in error_str.lower():
                    if attempt < max_retries - 1:
                        wait_time = 2 ** (attempt + 1)  # Exponential backoff
                        print(f"ğŸš€ [GROQ] âš ï¸  Rate limit error (429) - will retry in {wait_time}s...")
                        print(f"ğŸš€ [GROQ]    Error: {error_str}")
                        await asyncio.sleep(wait_time)
                        continue
                    else:
                        print(f"ğŸš€ [GROQ] âŒ Rate limit error (429) - max retries ({max_retries}) exceeded")
                        print(f"ğŸš€ [GROQ]    Error: {error_str}")
                        print(f"ğŸš€ [GROQ]    Please wait a few minutes and try again, or reduce groq_max_concurrent in config")
                        return None
                else:
                    # Other errors - don't retry
                    print(f"ğŸš€ [GROQ] âŒ Analysis error: {e}")
                    import traceback
                    print(f"ğŸš€ [GROQ] Full error traceback:")
                    traceback.print_exc()
                    debug_print(f"    âŒ Analysis error: {e}")
                    return None
        
        # If we get here, all retries failed
        print(f"ğŸš€ [GROQ] âŒ All {max_retries} retry attempts failed")
        return None
    
    def _parse_groq_response(self, response_text: str) -> List[Dict[str, str]]:
        """Parse Groq response into structured icon data (same format as Gemini)"""
        if not response_text:
            return []
        
        icons = []
        lines = response_text.strip().split('\n')
        
        for line in lines:
            line = line.strip()
            
            # Skip empty lines and lines that don't start with group identifiers
            if not line or not line.startswith(('H', 'V', 'U')):
                continue
            
            try:
                # Parse format: ID: "icon_name" | Usage: "brief explanation" | Enabled: "true/false" | Interactive: "true/false" | Type: "icon/text"
                if line.count('|') >= 4 and ':' in line:  # Now expect 5 parts
                    parts = line.split('|')
                    if len(parts) >= 5:
                        # Extract ID
                        id_part = parts[0].strip()
                        icon_id = id_part.split(':')[0].strip() if ':' in id_part else id_part
                        
                        # Extract name
                        name_part = parts[0].strip()
                        if ':' in name_part:
                            name = name_part.split(':', 1)[1].strip().strip('"').strip("'")
                        else:
                            name = "Unknown"
                        
                        # Extract usage
                        usage = parts[1].split(':', 1)[1].strip().strip('"').strip("'") if len(parts) > 1 and ':' in parts[1] else "No description"
                        
                        # Extract enabled
                        enabled_str = parts[2].split(':', 1)[1].strip().strip('"').strip("'").lower() if len(parts) > 2 and ':' in parts[2] else "true"
                        enabled = enabled_str == "true"
                        
                        # Extract interactive
                        interactive_str = parts[3].split(':', 1)[1].strip().strip('"').strip("'").lower() if len(parts) > 3 and ':' in parts[3] else "true"
                        interactive = interactive_str == "true"
                        
                        # Extract type
                        icon_type = parts[4].split(':', 1)[1].strip().strip('"').strip("'") if len(parts) > 4 and ':' in parts[4] else "icon"
                        
                        icons.append({
                            'id': icon_id,
                            'name': name,
                            'usage': usage,
                            'enabled': enabled,
                            'interactive': interactive,
                            'type': icon_type
                        })
            except Exception as e:
                debug_print(f"    âš ï¸  Error parsing line: {line} - {e}")
                continue
        
        return icons
    
    def _save_analysis_results(self, results: Dict[str, Any], filename_base: str = None) -> Optional[str]:
        """Save analysis results to JSON file"""
        if not self.save_results:
            return None
        
        try:
            os.makedirs(self.output_dir, exist_ok=True)
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            base_name = filename_base or "groq_analysis"
            results_path = os.path.join(self.output_dir, f"{base_name}_groq_results_{timestamp}.json")
            
            with open(results_path, "w", encoding="utf-8") as f:
                json.dump(results, f, indent=2, ensure_ascii=False)
            
            debug_print(f"ğŸ’¾ Saved Groq analysis results to: {results_path}")
            return results_path
        except Exception as e:
            debug_print(f"âŒ Error saving results: {e}")
            return None
    
    def _display_analysis_summary(self, results: Dict[str, Any]):
        """Display a summary of the analysis results"""
        print(f"\nğŸš€ [GROQ] ===== GROQ ANALYSIS SUMMARY =====")
        print(f"ğŸš€ [GROQ] âœ… Analyzed: {results['successful_analyses']}/{results['total_images_analyzed']} images")
        print(f"ğŸš€ [GROQ] ğŸ¯ Total icons found: {results['total_icons_found']}")
        print(f"ğŸš€ [GROQ] â±ï¸  Analysis time: {results['analysis_duration_seconds']:.2f}s")
        if results.get('results_saved_to'):
            print(f"ğŸš€ [GROQ] ğŸ’¾ Results saved to: {results['results_saved_to']}")
        print(f"ğŸš€ [GROQ] {'='*80}\n")

